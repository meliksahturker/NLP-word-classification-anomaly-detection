{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.compat.v1.keras.layers import CuDNNLSTM\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits = 10, random_state = 0, shuffle = True)\n",
    "\n",
    "#from tensorflow.python.client import device_lib\n",
    "#print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_metrics_together(y, probs, preds):\n",
    "    accuracy = metrics.accuracy_score(y, preds)\n",
    "    recall = metrics.recall_score(y, preds)\n",
    "    precision = metrics.precision_score(y, preds)\n",
    "    f1 = metrics.f1_score(y, preds)\n",
    "    auc = metrics.roc_auc_score(y, (probs))\n",
    "\n",
    "    df = pd.DataFrame({'Accuracy': accuracy, 'Recall': recall, 'Precision': precision, 'F1': f1, 'AUC': auc}, index = ['Score'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    }
   ],
   "source": [
    "char_to_num = {}\n",
    "letters = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "for idx, char in enumerate(letters):\n",
    "    char_to_num[char] = idx\n",
    "print(len(letters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validString(string):\n",
    "    string = str(string[0])\n",
    "    for char in string:\n",
    "        if char not in letters:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length of eng words: 20.0\n",
      "Number of English words: 25321\n"
     ]
    }
   ],
   "source": [
    "df_eng = pd.read_csv('English_25k.txt', header = None)\n",
    "mask = df_eng.apply(validString, axis = 1)\n",
    "df_eng = df_eng[mask]\n",
    "df_eng.columns = ['word']\n",
    "df_eng.drop_duplicates(inplace = True)\n",
    "df_eng['language'] = 1\n",
    "max_length_of_eng_words = df_eng['word'].str.len().value_counts().index.values.max()\n",
    "print('Max length of eng words:', max_length_of_eng_words)\n",
    "print('Number of English words:',df_eng.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length of tr words: 20\n",
      "Number of Turkish words: 86830\n"
     ]
    }
   ],
   "source": [
    "df_tr = pd.read_json('Turkish_92k.json')[['word']]\n",
    "replacement_map_for_tr = {' ': '', 'ç': 'c', 'ğ': 'g', 'ı': 'i', 'ö': 'o', 'ü': 'u', 'ş': 's', \n",
    "                          'â': 'a', 'î': 'i', 'i̇': 'i', 'û': 'u', '(': '', ')': '', ',': '', '-': ''}\n",
    "df_tr.loc[:, 'word'] = df_tr['word'].str.lower()\n",
    "for old_char in replacement_map_for_tr:\n",
    "    df_tr.loc[:, 'word'] = df_tr.loc[:, 'word'].str.replace(old_char, replacement_map_for_tr[old_char])\n",
    "    \n",
    "df_tr = df_tr[df_tr['word'].str.len() <= 20].reset_index(drop = True)\n",
    "df_tr = df_tr[df_tr.apply(validString, axis = 1)]\n",
    "df_tr.drop_duplicates(inplace = True)\n",
    "max_length_of_tr_words = df_tr['word'].str.len().value_counts().index.values.max()\n",
    "df_tr['language'] = 0\n",
    "print('Max length of tr words:', max_length_of_tr_words)\n",
    "print('Number of Turkish words:',df_tr.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_word_len = max(max_length_of_tr_words, max_length_of_eng_words)\n",
    "def word_to_vec(word):\n",
    "    zeros = np.zeros(26)\n",
    "    word_vec = []\n",
    "    # padding\n",
    "    for i in range(max_word_len - len(str(word))):\n",
    "        word_vec.append(zeros)\n",
    "        \n",
    "    for char in str(word):\n",
    "        char_vec = np.zeros(26)\n",
    "        char_vec[char_to_num[char]] = 1\n",
    "        word_vec.append(char_vec)\n",
    "    return np.array(word_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4958</th>\n",
       "      <td>cosmically</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15246</th>\n",
       "      <td>darulfunun</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86578</th>\n",
       "      <td>hangibir</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             word  language\n",
       "4958   cosmically         1\n",
       "15246  darulfunun         0\n",
       "86578    hangibir         0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df_tr, df_eng])\n",
    "df = df.sample(frac=1).drop_duplicates(subset = 'word')\n",
    "y = df['language'].values\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X = []\n",
    "for word in df['word']:\n",
    "    word_vec = word_to_vec(word)\n",
    "    X.append(word_vec)\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 completed\n",
      "Fold 2 completed\n",
      "Fold 3 completed\n",
      "Fold 4 completed\n",
      "Fold 5 completed\n",
      "Fold 6 completed\n",
      "Fold 7 completed\n",
      "Fold 8 completed\n",
      "Fold 9 completed\n",
      "Fold 10 completed\n",
      "Wall time: 24min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "epochs = 250\n",
    "batch_size = 256\n",
    "earlystopping = EarlyStopping(monitor='val_loss', patience = 10, restore_best_weights = True)\n",
    "\n",
    "lst_y = np.array([])\n",
    "lst_yhat = np.array([])\n",
    "lst_yhat_probs = np.array([])\n",
    "lst_X_test = np.array([]).reshape((0, 20, 26))\n",
    "\n",
    "fold = 1\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    lst_X_test = np.concatenate([lst_X_test, X_test])\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(max_word_len, input_shape = (max_word_len, 26)))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    model.compile(loss = 'mean_squared_error', optimizer = 'Adam')\n",
    "    model.fit(X_train, y_train, epochs = epochs, batch_size = batch_size, verbose = 0, validation_data = (X_test, y_test),\n",
    "             use_multiprocessing = True, callbacks=[earlystopping])\n",
    "    \n",
    "    \n",
    "    y_hat_probs = model.predict(X_test).reshape(-1)\n",
    "    y_fold_preds = (y_hat_probs >= 0.5) * 1\n",
    "    \n",
    "    lst_y = np.concatenate([lst_y, y_test])\n",
    "    lst_yhat = np.concatenate([lst_yhat, y_fold_preds])\n",
    "    lst_yhat_probs = np.concatenate([lst_yhat_probs, y_hat_probs])\n",
    "    \n",
    "    print('Fold', fold, 'completed')\n",
    "    fold += 1\n",
    "    \n",
    "y_test = lst_y.astype(int)\n",
    "y_hat = lst_yhat.astype(int)\n",
    "y_probs = lst_yhat_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Score</th>\n",
       "      <td>0.963799</td>\n",
       "      <td>0.914063</td>\n",
       "      <td>0.924727</td>\n",
       "      <td>0.919364</td>\n",
       "      <td>0.992553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Accuracy    Recall  Precision        F1       AUC\n",
       "Score  0.963799  0.914063   0.924727  0.919364  0.992553"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_metrics_together(y_test, y_probs, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mispred_mask = y_test != y_hat\n",
    "mispreds = lst_X_test[mispred_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Vector to Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "mispred_words = []\n",
    "for word_vec in mispreds:\n",
    "    word = ''\n",
    "    for char_vec in word_vec:\n",
    "        if not any(char_vec):\n",
    "            char = ''\n",
    "        else:\n",
    "            char = letters[np.argmax(char_vec)]\n",
    "        word = word + char\n",
    "        \n",
    "    mispred_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "mispred_df = pd.DataFrame({'word': mispred_words, 'y': y_test[mispred_mask], 'y_hat': y_hat[mispred_mask]})\n",
    "mispred_df = mispred_df.astype(str)\n",
    "mispred_df.loc[:, 'y'] = mispred_df.loc[:, 'y'].str.replace('0', 'tr').str.replace('1', 'eng')\n",
    "mispred_df.loc[:, 'y_hat'] = mispred_df.loc[:, 'y_hat'].str.replace('0', 'tr').str.replace('1', 'eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>y</th>\n",
       "      <th>y_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>bayou</td>\n",
       "      <td>eng</td>\n",
       "      <td>tr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>fenomenist</td>\n",
       "      <td>tr</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3227</th>\n",
       "      <td>disk</td>\n",
       "      <td>tr</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1775</th>\n",
       "      <td>thinktank</td>\n",
       "      <td>tr</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3981</th>\n",
       "      <td>optometrist</td>\n",
       "      <td>eng</td>\n",
       "      <td>tr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>farad</td>\n",
       "      <td>tr</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2243</th>\n",
       "      <td>delta</td>\n",
       "      <td>eng</td>\n",
       "      <td>tr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>antre</td>\n",
       "      <td>tr</td>\n",
       "      <td>eng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>testosterone</td>\n",
       "      <td>eng</td>\n",
       "      <td>tr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3510</th>\n",
       "      <td>kidder</td>\n",
       "      <td>eng</td>\n",
       "      <td>tr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              word    y y_hat\n",
       "228          bayou  eng    tr\n",
       "1002    fenomenist   tr   eng\n",
       "3227          disk   tr   eng\n",
       "1775     thinktank   tr   eng\n",
       "3981   optometrist  eng    tr\n",
       "51           farad   tr   eng\n",
       "2243         delta  eng    tr\n",
       "1229         antre   tr   eng\n",
       "800   testosterone  eng    tr\n",
       "3510        kidder  eng    tr"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mispred_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with Whole Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xaa1c798340>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 500\n",
    "batch_size = 256\n",
    "earlystopping = EarlyStopping(monitor='loss', patience = 10, restore_best_weights = True)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(max_word_len, input_shape = (max_word_len, 26), dropout = 0.2))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'Adam')\n",
    "model.fit(X, y, epochs = epochs, batch_size = batch_size, verbose = 0,\n",
    "         use_multiprocessing = True, callbacks=[earlystopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Your Own Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word meliksah was NOT in training data\n",
      "meliksah is predicted to be a Turkish word with probability 1.00\n"
     ]
    }
   ],
   "source": [
    "word = 'meliksah'\n",
    "\n",
    "prob = model.predict(word_to_vec(word).reshape(1, 20, 26))\n",
    "if word in df['word'].values:\n",
    "    print(\"Word\", word, 'was in training data')\n",
    "else:\n",
    "    print(\"Word\", word, 'was NOT in training data')\n",
    "    \n",
    "    \n",
    "if prob >= 0.5:\n",
    "    print(word, 'is predicted to be an English word with probability %.2f' %prob[0][0])\n",
    "else:\n",
    "    print(word, 'is predicted to be a Turkish word with probability %.2f' %(1-prob[0][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
